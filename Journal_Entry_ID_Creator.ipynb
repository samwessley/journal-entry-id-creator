{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“Š Journal Entry ID Creator\n",
        "\n",
        "**Automatically create balanced journal entries from your Excel data in 3 simple steps!**\n",
        "\n",
        "This tool will:\n",
        "- âœ… Create balanced journal entries (debits = credits)\n",
        "- âœ… Group lines by date and matching fields\n",
        "- âœ… Assign Journal IDs to every line\n",
        "- âœ… Handle minimum 2-line requirement\n",
        "- âœ… Download results instantly\n",
        "\n",
        "## ğŸš€ Instructions:\n",
        "1. **Run the setup** (click â–¶ï¸ on the cell below)\n",
        "2. **Upload your Excel file** when prompted\n",
        "3. **Download your results** with Journal IDs added\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ”§ **STEP 1: Setup & Configuration** { display-mode: \"form\" }\n",
        "# @markdown Click the â–¶ï¸ button to install required packages and load the journal entry creator.\n",
        "\n",
        "print(\"ğŸ”§ Setting up Journal Entry ID Creator...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
        "\n",
        "try:\n",
        "    install_package(\"pandas\")\n",
        "    install_package(\"openpyxl\")\n",
        "    print(\"âœ… Required packages installed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error installing packages: {e}\")\n",
        "\n",
        "# Import libraries\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from itertools import combinations\n",
        "    import io\n",
        "    from pathlib import Path\n",
        "    from google.colab import files\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "    print(\"âœ… Libraries imported successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error importing libraries: {e}\")\n",
        "\n",
        "# Load the Journal Entry Creator (implementation hidden)\n",
        "exec('''\n",
        "class JournalEntryCreator:\n",
        "    def __init__(self):\n",
        "        self.journal_lines = None\n",
        "        self.grouped_entries = {}\n",
        "        self.unassigned_lines = []\n",
        "        \n",
        "    def _normalize_and_deduplicate_columns(self, columns):\n",
        "        normalized = []\n",
        "        for col in columns:\n",
        "            name = '' if pd.isna(col) else str(col).strip()\n",
        "            if name.lower() in ('', 'nan', 'none'):\n",
        "                name = 'Unnamed'\n",
        "            normalized.append(name)\n",
        "        seen = {}\n",
        "        unique_cols = []\n",
        "        for name in normalized:\n",
        "            count = seen.get(name, 0)\n",
        "            unique_name = f\"{name}_{count}\" if count > 0 else name\n",
        "            seen[name] = count + 1\n",
        "            unique_cols.append(unique_name)\n",
        "        return unique_cols\n",
        "        \n",
        "    def load_data_from_uploaded_file(self, uploaded_file_data, filename):\n",
        "        \"\"\"Load journal lines from uploaded Excel file data\"\"\"\n",
        "        try:\n",
        "            df_all = pd.read_excel(io.BytesIO(uploaded_file_data), header=None)\n",
        "            \n",
        "            if len(df_all) == 0:\n",
        "                print(\"No data found in Excel file.\")\n",
        "                return False\n",
        "            \n",
        "            first_row = df_all.iloc[0].values\n",
        "            second_row = df_all.iloc[1].values if len(df_all) > 1 else None\n",
        "            \n",
        "            if second_row is not None and isinstance(second_row[0], str) and 'Posted Date' in str(second_row[0]):\n",
        "                print(\"âœ… Detected field names in second row\")\n",
        "                template_row = second_row\n",
        "                df = df_all.iloc[2:].copy()\n",
        "            elif isinstance(first_row[0], str) and 'Posted Date' in str(first_row[0]):\n",
        "                print(\"âœ… Detected template headers in first row\")\n",
        "                template_row = first_row\n",
        "                df = df_all.iloc[1:].copy()\n",
        "            else:\n",
        "                print(\"âœ… Using default column structure\")\n",
        "                template_row = ['Posted Date', 'Account ID', 'Debit Amount', 'Credit Amount'] + [f'Optional_{i}' for i in range(len(df_all.columns) - 4)]\n",
        "                df = df_all.copy()\n",
        "            \n",
        "            if len(df) == 0:\n",
        "                print(\"âŒ No data found. Please add journal line data.\")\n",
        "                return False\n",
        "            \n",
        "            df.columns = self._normalize_and_deduplicate_columns(template_row[:len(df.columns)])\n",
        "            df = df.dropna(how='all')\n",
        "            \n",
        "            required_cols = ['Posted Date', 'Account ID', 'Debit Amount', 'Credit Amount']\n",
        "            for col in required_cols:\n",
        "                if col not in df.columns:\n",
        "                    print(f\"âŒ Required column '{col}' not found\")\n",
        "                    return False\n",
        "            \n",
        "            df['Posted Date'] = pd.to_datetime(df['Posted Date'])\n",
        "            df['Debit Amount'] = pd.to_numeric(df['Debit Amount'], errors='coerce').fillna(0)\n",
        "            df['Credit Amount'] = pd.to_numeric(df['Credit Amount'], errors='coerce').fillna(0)\n",
        "            df['_row_index'] = range(len(df))\n",
        "            \n",
        "            self.journal_lines = df\n",
        "            print(f\"ğŸ“Š Loaded {len(df)} journal lines from {filename}\")\n",
        "            # Debug columns\n",
        "            print(\"Columns:\", list(df.columns))\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error loading Excel file: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def get_optional_fields(self):\n",
        "        if self.journal_lines is None:\n",
        "            return []\n",
        "        \n",
        "        required_cols = ['Posted Date', 'Account ID', 'Debit Amount', 'Credit Amount', '_row_index']\n",
        "        optional_cols = []\n",
        "        \n",
        "        for col in self.journal_lines.columns:\n",
        "            if col not in required_cols:\n",
        "                try:\n",
        "                    non_empty = self.journal_lines[col].notna() & (self.journal_lines[col] != '') & (self.journal_lines[col] != '[INSERT FIELD NAME]')\n",
        "                    if non_empty.any():\n",
        "                        optional_cols.append(col)\n",
        "                except:\n",
        "                    continue\n",
        "        return optional_cols\n",
        "    \n",
        "    def check_balance(self, group_df):\n",
        "        if len(group_df) < 2:\n",
        "            return False\n",
        "        total_debits = group_df['Debit Amount'].sum()\n",
        "        total_credits = group_df['Credit Amount'].sum()\n",
        "        return abs(total_debits - total_credits) < 0.01\n",
        "    \n",
        "    def generate_grouping_combinations(self, optional_fields, max_fields=5):\n",
        "        combinations_to_try = []\n",
        "        for r in range(min(len(optional_fields), max_fields), 0, -1):\n",
        "            for combo in combinations(optional_fields, r):\n",
        "                combinations_to_try.append(['Posted Date'] + list(combo))\n",
        "        combinations_to_try.append(['Posted Date'])\n",
        "        return combinations_to_try\n",
        "    \n",
        "    def create_journal_entries(self, max_optional_fields=5):\n",
        "        if self.journal_lines is None:\n",
        "            print(\"âŒ No data loaded\")\n",
        "            return False\n",
        "        \n",
        "        print(\"ğŸ”„ Creating journal entries...\")\n",
        "        \n",
        "        optional_fields = self.get_optional_fields()\n",
        "        print(f\"ğŸ“‹ Found optional fields: {optional_fields}\")\n",
        "        \n",
        "        field_combinations = self.generate_grouping_combinations(optional_fields, max_optional_fields)\n",
        "        print(f\"ğŸ” Testing {len(field_combinations)} grouping combinations...\")\n",
        "        \n",
        "        assigned_lines = set()\n",
        "        journal_entry_id = 1\n",
        "        \n",
        "        for fields in field_combinations:\n",
        "            # Get unassigned lines and reset index to avoid groupby issues\n",
        "            unassigned_df = self.journal_lines[~self.journal_lines['_row_index'].isin(assigned_lines)].copy().reset_index(drop=True)\n",
        "            \n",
        "            if len(unassigned_df) == 0:\n",
        "                break\n",
        "            \n",
        "            # Dedupe and validate grouping fields\n",
        "            valid_fields = [col for col in fields if col in unassigned_df.columns]\n",
        "            valid_fields = list(dict.fromkeys(valid_fields))\n",
        "            if not valid_fields:\n",
        "                continue\n",
        "            \n",
        "            try:\n",
        "                grouped = unassigned_df.groupby(valid_fields, dropna=False, sort=False)\n",
        "            except Exception as e:\n",
        "                print(f\"   Error grouping by {valid_fields}: {e}\")\n",
        "                continue\n",
        "            \n",
        "            balanced_groups = 0\n",
        "            \n",
        "            for group_key, group_df in grouped:\n",
        "                if self.check_balance(group_df):\n",
        "                    je_id = f\"JE{journal_entry_id:04d}\"\n",
        "                    \n",
        "                    group_df_clean = group_df.copy().reset_index(drop=True)\n",
        "                    \n",
        "                    self.grouped_entries[je_id] = {\n",
        "                        'lines': group_df_clean,\n",
        "                        'grouping_fields': valid_fields,\n",
        "                        'group_key': group_key,\n",
        "                        'total_debits': group_df_clean['Debit Amount'].sum(),\n",
        "                        'total_credits': group_df_clean['Credit Amount'].sum()\n",
        "                    }\n",
        "                    \n",
        "                    assigned_lines.update(group_df['_row_index'].tolist())\n",
        "                    journal_entry_id += 1\n",
        "                    balanced_groups += 1\n",
        "            \n",
        "            if balanced_groups > 0:\n",
        "                print(f\"   âœ… Created {balanced_groups} entries with grouping: {valid_fields}\")\n",
        "        \n",
        "        # Handle remaining lines\n",
        "        remaining_lines = self.journal_lines[~self.journal_lines['_row_index'].isin(assigned_lines)].copy().reset_index(drop=True)\n",
        "        \n",
        "        if len(remaining_lines) > 0:\n",
        "            print(f\"ğŸ“ Processing {len(remaining_lines)} remaining lines...\")\n",
        "            \n",
        "            for _, line in remaining_lines.iterrows():\n",
        "                debit = line['Debit Amount']\n",
        "                credit = line['Credit Amount']\n",
        "                line_date = line['Posted Date']\n",
        "                \n",
        "                if debit == 0 and credit == 0:\n",
        "                    assigned_to_existing = False\n",
        "                    for je_id, entry_data in self.grouped_entries.items():\n",
        "                        entry_date = entry_data['lines']['Posted Date'].iloc[0]\n",
        "                        if entry_date.date() == line_date.date():\n",
        "                            line_df = pd.DataFrame([line]).reset_index(drop=True)\n",
        "                            entry_data['lines'] = pd.concat([entry_data['lines'].reset_index(drop=True), line_df], ignore_index=True)\n",
        "                            entry_data['total_debits'] += line['Debit Amount']\n",
        "                            entry_data['total_credits'] += line['Credit Amount']\n",
        "                            assigned_lines.add(line['_row_index'])\n",
        "                            assigned_to_existing = True\n",
        "                            print(f\"   âœ… Zero-amount line assigned to {je_id}\")\n",
        "                            break\n",
        "                    if not assigned_to_existing:\n",
        "                        je_id = f\"JE{journal_entry_id:04d}\"\n",
        "                        line_df = pd.DataFrame([line]).reset_index(drop=True)\n",
        "                        self.grouped_entries[je_id] = {\n",
        "                            'lines': line_df,\n",
        "                            'grouping_fields': ['Zero Amount Entry'],\n",
        "                            'group_key': f\"Zero amount: {line['Account ID']}\",\n",
        "                            'total_debits': debit,\n",
        "                            'total_credits': credit\n",
        "                        }\n",
        "                        assigned_lines.add(line['_row_index'])\n",
        "                        journal_entry_id += 1\n",
        "                elif debit != 0 and credit != 0:\n",
        "                    continue\n",
        "                else:\n",
        "                    je_id = f\"JE{journal_entry_id:04d}\"\n",
        "                    line_df = pd.DataFrame([line]).reset_index(drop=True)\n",
        "                    self.grouped_entries[je_id] = {\n",
        "                        'lines': line_df,\n",
        "                        'grouping_fields': ['Individual Entry'],\n",
        "                        'group_key': f\"Single line: {line['Account ID']}\",\n",
        "                        'total_debits': debit,\n",
        "                        'total_credits': credit\n",
        "                    }\n",
        "                    assigned_lines.add(line['_row_index'])\n",
        "                    journal_entry_id += 1\n",
        "        \n",
        "        self.unassigned_lines = self.journal_lines[~self.journal_lines['_row_index'].isin(assigned_lines)].copy()\n",
        "        \n",
        "        print(f\"\\\\nğŸ“Š Summary:\")\n",
        "        print(f\"   âœ… Journal entries created: {len(self.grouped_entries)}\")\n",
        "        print(f\"   âœ… Lines assigned: {len(assigned_lines)}\")\n",
        "        print(f\"   âš ï¸  Invalid lines: {len(self.unassigned_lines)}\")\n",
        "        \n",
        "        return True\n",
        "    \n",
        "    def generate_output(self, original_filename):\n",
        "        if self.journal_lines is None:\n",
        "            return None\n",
        "        \n",
        "        output_df = self.journal_lines.copy()\n",
        "        output_df['Journal ID'] = ''\n",
        "        \n",
        "        for je_id, entry_data in self.grouped_entries.items():\n",
        "            row_indices = entry_data['lines']['_row_index'].tolist()\n",
        "            output_df.loc[output_df['_row_index'].isin(row_indices), 'Journal ID'] = je_id\n",
        "        \n",
        "        output_df = output_df.drop('_row_index', axis=1)\n",
        "        \n",
        "        cols = list(output_df.columns)\n",
        "        cols.remove('Journal ID')\n",
        "        posted_date_idx = cols.index('Posted Date')\n",
        "        cols.insert(posted_date_idx, 'Journal ID')\n",
        "        output_df = output_df[cols]\n",
        "        \n",
        "        input_path = Path(original_filename)\n",
        "        output_filename = f\"{input_path.stem}_with_journal_ids{input_path.suffix}\"\n",
        "        \n",
        "        output_buffer = io.BytesIO()\n",
        "        output_df.to_excel(output_buffer, index=False)\n",
        "        output_buffer.seek(0)\n",
        "        \n",
        "        self.print_summary_report()\n",
        "        \n",
        "        return output_buffer.getvalue(), output_filename\n",
        "    \n",
        "    def print_summary_report(self):\n",
        "        print(\"\\\\n\" + \"=\"*50)\n",
        "        print(\"ğŸ“‹ JOURNAL ENTRY SUMMARY\")\n",
        "        print(\"=\"*50)\n",
        "        \n",
        "        multi_line_entries = []\n",
        "        single_line_entries = []\n",
        "        \n",
        "        for je_id, entry_data in sorted(self.grouped_entries.items()):\n",
        "            if len(entry_data['lines']) > 1:\n",
        "                multi_line_entries.append((je_id, entry_data))\n",
        "            else:\n",
        "                single_line_entries.append((je_id, entry_data))\n",
        "        \n",
        "        if multi_line_entries:\n",
        "            print(f\"\\\\nğŸ”— MULTI-LINE ENTRIES ({len(multi_line_entries)}):\")\n",
        "            for je_id, entry_data in multi_line_entries[:5]:\n",
        "                lines = entry_data['lines']\n",
        "                print(f\"   {je_id}: {lines['Posted Date'].iloc[0].strftime('%Y-%m-%d')} | {len(lines)} lines | ${entry_data['total_debits']:,.2f}\")\n",
        "            \n",
        "            if len(multi_line_entries) > 5:\n",
        "                print(f\"   ... and {len(multi_line_entries) - 5} more\")\n",
        "        \n",
        "        if single_line_entries:\n",
        "            print(f\"\\\\nğŸ“„ SINGLE-LINE ENTRIES ({len(single_line_entries)}):\")\n",
        "            for je_id, entry_data in single_line_entries[:3]:\n",
        "                lines = entry_data['lines']\n",
        "                line = lines.iloc[0]\n",
        "                print(f\"   {je_id}: {line['Posted Date'].strftime('%Y-%m-%d')} | {line['Account ID']} | ${line['Debit Amount']:.2f}/${line['Credit Amount']:.2f}\")\n",
        "            \n",
        "            if len(single_line_entries) > 3:\n",
        "                print(f\"   ... and {len(single_line_entries) - 3} more\")\n",
        "''')\n",
        "\n",
        "print(\"âœ… Journal Entry Creator loaded successfully!\")\n",
        "print(\"\\nğŸ¯ Ready to process your Excel file!\")\n",
        "print(\"   â¬‡ï¸ Run the next cell to upload your file\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ“ **STEP 2: Upload Your Excel File** { display-mode: \"form\" }\n",
        "# @markdown Click â–¶ï¸ to upload your Excel file with journal line data.\n",
        "\n",
        "print(\"ğŸ“ Upload Your Excel File\")\n",
        "print(\"=\" * 30)\n",
        "print(\"Your file should contain:\")\n",
        "print(\"   âœ… Posted Date column\")\n",
        "print(\"   âœ… Account ID column\") \n",
        "print(\"   âœ… Debit Amount column\")\n",
        "print(\"   âœ… Credit Amount column\")\n",
        "print(\"   ğŸ“‹ Optional fields (Description, Reference, etc.)\")\n",
        "print()\n",
        "\n",
        "# Upload file\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    file_data = uploaded[filename]\n",
        "    print(f\"\\nâœ… Successfully uploaded: {filename}\")\n",
        "    print(f\"   ğŸ“Š File size: {len(file_data):,} bytes\")\n",
        "    \n",
        "    # Process immediately\n",
        "    print(\"\\nğŸš€ Processing your data...\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    creator = JournalEntryCreator()\n",
        "    \n",
        "    if creator.load_data_from_uploaded_file(file_data, filename):\n",
        "        if creator.create_journal_entries():\n",
        "            output_data, output_filename = creator.generate_output(filename)\n",
        "            \n",
        "            print(f\"\\nğŸ‰ SUCCESS! Your file is ready for download.\")\n",
        "            print(f\"   ğŸ“„ Output filename: {output_filename}\")\n",
        "            print(\"\\nâ¬‡ï¸ Run the next cell to download your results!\")\n",
        "        else:\n",
        "            print(\"âŒ Failed to create journal entries\")\n",
        "    else:\n",
        "        print(\"âŒ Failed to load your Excel file\")\n",
        "else:\n",
        "    print(\"âŒ No file uploaded. Please run this cell again.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ’¾ **STEP 3: Download Your Results** { display-mode: \"form\" }\n",
        "# @markdown Click â–¶ï¸ to download your processed Excel file with Journal IDs.\n",
        "\n",
        "if 'output_data' in locals() and 'output_filename' in locals():\n",
        "    print(\"ğŸ’¾ Downloading Your Results\")\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    # Save and download the file\n",
        "    with open(output_filename, 'wb') as f:\n",
        "        f.write(output_data)\n",
        "    \n",
        "    files.download(output_filename)\n",
        "    \n",
        "    print(f\"âœ… Download started: {output_filename}\")\n",
        "    print(\"\\nğŸ“‹ Your output file contains:\")\n",
        "    print(\"   âœ… All your original data\")\n",
        "    print(\"   âœ… New 'Journal ID' column\")\n",
        "    print(\"   âœ… Every line has a Journal ID\")\n",
        "    print(\"   âœ… Balanced journal entries\")\n",
        "    print(\"   âœ… Zero-amount lines properly assigned\")\n",
        "    \n",
        "    print(\"\\nğŸ¯ Next Steps:\")\n",
        "    print(\"   ğŸ“Š Import into your accounting system\")\n",
        "    print(\"   ğŸ“ˆ Use Journal IDs for reporting\")\n",
        "    print(\"   ğŸ” Review the summary above\")\n",
        "    \n",
        "    print(\"\\nâœ¨ Thank you for using Journal Entry ID Creator!\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ No processed data available.\")\n",
        "    print(\"   Please run the previous cell to upload and process your file first.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
